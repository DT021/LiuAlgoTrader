{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"TSLA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "import alpaca_trade_api as tradeapi\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from fastai.data.all import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tradeapi.REST(base_url=\"https://api.alpaca.markets\")\n",
    "ohlc_data = api.polygon.historic_agg_v2(\n",
    "    symbol,\n",
    "    1,\n",
    "    \"minute\",\n",
    "    _from=str(date.today() - timedelta(days=9)),\n",
    "    to=str(date.today()),\n",
    ").df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dates = ohlc_data.index\n",
    "ohlc_data['date'] = np.arange(start = 0, stop = len(ohlc_data), step = 1, dtype='int')\n",
    "ohlc_data=ohlc_data.set_index(ohlc_data.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc_data.close.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#ohlc_data['reshaped'] = scaler.fit_transform(ohlc_data.close.values.reshape(-1, 1)).flatten()\n",
    "open = scaler.fit_transform(ohlc_data.open.values.reshape(-1, 1)).flatten()\n",
    "high = scaler.fit_transform(ohlc_data.high.values.reshape(-1, 1)).flatten()\n",
    "low = scaler.fit_transform(ohlc_data.low.values.reshape(-1, 1)).flatten()\n",
    "close = scaler.fit_transform(ohlc_data.close.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "df(close).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_size = 120\n",
    "\n",
    "train_data_close = close[2:-test_data_size]\n",
    "test_data = close[-test_data_size:]\n",
    "test_data_normalized = torch.FloatTensor(test_data).view(-1)\n",
    "test_data_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_close = pd.Series(train_data_close.tolist())\n",
    "train_data_normalized = torch.FloatTensor(train_data_close)\n",
    "train_data_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = 60\n",
    "\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L - tw):\n",
    "        train_seq = input_data[i : i + tw]\n",
    "        train_label = input_data[i + tw : i + tw + 1]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in_seq = create_inout_sequences(train_data_normalized, train_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size , num_layers=2,dropout=0.5,bidirectional=False)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(2,1,self.hidden_layer_size),\n",
    "                            torch.zeros(2,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, 1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_in_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (\n",
    "            torch.zeros(2, 1, model.hidden_layer_size),\n",
    "            torch.zeros(2, 1, model.hidden_layer_size),\n",
    "        )\n",
    "\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i % 25 == 1:\n",
    "        print(f\"epoch: {i:3} loss: {single_loss.item():10.8f}\")\n",
    "\n",
    "print(f\"epoch: {i:3} loss: {single_loss.item():10.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = test_data_normalized.tolist()\n",
    "test= df(test_data_normalized)\n",
    "test.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "train_data_normalized = torch.FloatTensor(train_data_close)\n",
    "train_data_normalized.shape\n",
    "\n",
    "predicted = test_data_normalized[:train_window].tolist()\n",
    "print(len(predicted))\n",
    "for i in range(test_data_size - train_window):\n",
    "    seq = torch.FloatTensor(predicted[-train_window:])\n",
    "    with torch.no_grad():\n",
    "        model.hidden_cell = (\n",
    "            torch.zeros(2, 1, model.hidden_layer_size),\n",
    "            torch.zeros(2, 1, model.hidden_layer_size),\n",
    "        )\n",
    "        item = model(seq).item()\n",
    "        predicted.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = df(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f'{symbol} LSTM predictions')\n",
    "plt.grid(True)\n",
    "plt.autoscale(axis='x', tight=True)\n",
    "plt.plot(test)\n",
    "plt.plot(predicted)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
